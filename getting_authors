### first attempt at scraping for Hackathon 
#Luke Meyers 6:04 6/24

from distutils.filelist import findall
import matplotlib as mpl
from matplotlib.pyplot import table
#import 
from requests import *
import sys 

sys.path.insert(0,r"C:\Anaconda3\pkgs\beautifulsoup4-4.11.1-py39haa95532_0\Lib\site-packages\bs4")

from bs4 import *
import selenium as sl
import csv


person = 'KM+Hultgren'

search = get("https://scholar.google.com/scholar?&q="+person+"&hl=en&as_sdt=0,5")


#search.json()
#print(search.content)

soup= BeautifulSoup(search.content,'html.parser')
#print(soup.prettify())

table = soup.find('div',attrs={'id':'gs_res_ccl_mid'})
results = [] 


def titleParse(dump):
    '''parses the title from the output of a html dump'''
    dumpStr = str(dump)
    titles = []
    for i in range(len(dumpStr)):
        if dumpStr[i] == '<':
            if dumpStr[i+1] == '/':
                if dumpStr[i+2] == 'a':
                    status = False
                    ix = i-1 
                    title = ''
                    while status == False:
                        title = title + dumpStr[ix]
                        ix = ix-1 
                        if dumpStr[ix] == '>':
                            status = True 
                    titles.append(reverseStr(title))
    return titles 
    
def reverseStr(strIn):
    '''returns a string backwards'''
    out = ''
    for char in strIn:
        out = char + out 
    return out 

def cleanHTML(strIn):
    '''gets rid of anything in <>'''
    strOut = ''
    strIn = str(strIn)
    #print(strIn)
    perm = True
    for i in range(len(strIn)):
        if strIn[i] == '<':
            perm = False
        elif strIn[i-1] == '>':
            if strIn[i-2] != '<' or '>':
                perm = True 
        if perm == True: 
            strOut = strOut + strIn[i]
    return strOut

def cleanList(listIn):
    '''does cleanHTML but to a list'''
    listOut = []
    for i in listIn:
        listOut.append(cleanHTML(i))
    return listOut

def countSpaces(strIn):
    '''returns the num of spaces in a str'''
    count = 0 
    for c in strIn:
        if c == ' ':
            count = count +1
    return count 


def listAuthors(aIn):
    '''receives how the authors were listed on google scholars and
    returns them as a list'''
    listOut = [] 
    proc = str(aIn)
    stops = [',','.','-','\u2026'] #unicode char for ellipsis
    for i in range(len(proc)):
        if proc[i] in stops :
            nameComp = False
            name = ''
            tckr = i-1
            while nameComp == False:
                if proc[tckr] != '[':
                    name = proc[tckr]+name
                tckr = tckr-1
                if proc[tckr] in stops:
                    nameComp = True
                elif tckr < 0:
                    name = ' '+name
                    nameComp = True 
            #if u'\xao' in name:
                #name = name[:-3]
            name = name.replace(u'\xa0',' ')
            if countSpaces(name[0:4]) >= 2:
                listOut.append(name)
    #now I need to get rid of the items that are not names  
    return listOut  


def getDump(results,type='title'):
    tDump = []
    aDump1 = []
    aFinal = [] 
    for row in results.findAll('div',attrs={'class':'gs_r gs_or gs_scl'}):
        authorDump = row.findAll('div',attrs={'class':'gs_a'})
        aDump1.append(authorDump)
        titleDump = row.findAll('div',attrs={'class':'gs_ri'})
        for dump in titleDump:
            title = dump.findAll('h3',attrs={'class':'gs_rt'})
            tDump.append(titleParse(title))
    if type == 'title':
        return tDump
    elif type == 'author':
        for a in aDump1:
            #print(str(cleanHTML(a)))
            aFinal.append((listAuthors(cleanHTML(a))))
            #print(cleanHTML(a))
        return aFinal 

def getUniqName(listIn):
    '''returns a list of all unique names in Dump'''
    listOut = []
    for i in listIn:
        if type(i)== list:
            for n in i: 
                if n in listOut:
                    placeholder =0
                else:
                    listOut.append(n)
    return listOut 



authors = getDump(table,'author')

read = getUniqName(authors)

print(read)

def authors2csv(filename,aList,a):
    with open(filename,'w') as csvfile:
        fileW = csv.writer(csvfile,delimiter= ',',
                        quotechar='|',quoting=csv.QUOTE_MINIMAL)
        for n in aList:
            fileW.writerow([n,a])

authors2csv('authors.csv',read,'KM Hultgren')

#@print(content)
print('ran')



